{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b67a6652-66ab-4899-8701-310a86935fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import pipeline\n",
    "from unsloth import FastLanguageModel\n",
    "from typing import Dict\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f6bb6e4-cd73-4962-90e3-d92be93690f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is a high school diploma required for an F-1 v...</td>\n",
       "      <td>A high school diploma or its equivalent is gen...</td>\n",
       "      <td>Question Understanding\\nThe question asks whet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is it important to memorize my SEVIS ID?</td>\n",
       "      <td>It's crucial to know your SEVIS ID, as it's yo...</td>\n",
       "      <td>Question Understanding\\nThe question asks abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is proof of housing required at the port of en...</td>\n",
       "      <td>While proof of housing is not always required ...</td>\n",
       "      <td>Question Understanding\\nThe question asks whet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What document does a school provide for an F-1...</td>\n",
       "      <td>A school provides Form I-20, a Certificate of ...</td>\n",
       "      <td>Question Understanding\\nThe question asks abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What if I plan to do research collaboration wi...</td>\n",
       "      <td>If asked about potential research collaboratio...</td>\n",
       "      <td>Question Understanding\\nThe question concerns ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  Is a high school diploma required for an F-1 v...   \n",
       "1           Is it important to memorize my SEVIS ID?   \n",
       "2  Is proof of housing required at the port of en...   \n",
       "3  What document does a school provide for an F-1...   \n",
       "4  What if I plan to do research collaboration wi...   \n",
       "\n",
       "                                              Answer  \\\n",
       "0  A high school diploma or its equivalent is gen...   \n",
       "1  It's crucial to know your SEVIS ID, as it's yo...   \n",
       "2  While proof of housing is not always required ...   \n",
       "3  A school provides Form I-20, a Certificate of ...   \n",
       "4  If asked about potential research collaboratio...   \n",
       "\n",
       "                                           reasoning  \n",
       "0  Question Understanding\\nThe question asks whet...  \n",
       "1  Question Understanding\\nThe question asks abou...  \n",
       "2  Question Understanding\\nThe question asks whet...  \n",
       "3  Question Understanding\\nThe question asks abou...  \n",
       "4  Question Understanding\\nThe question concerns ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../dataset/cleaned_dataset_answer_improved_reasoned.csv\", encoding=\"utf-8\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b32deb63-60e6-461d-aa50-368741d5c02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c17816bf-0821-41fd-8b62-9ca06adaa072",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Jenitza182/Qwen2.5-7B-Instruct-law-lora_model'  # Jenitza182/Meta-Llama-3.1-8B-Instruct-law-lora_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2d9e0cb-48b1-4ba3-bb3e-1d0666f61ddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.2.15: Fast Qwen2 patching. Transformers: 4.49.0.\n",
      "   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.381 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d88b7c50684661b06be695315346c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.2.15 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Qwen2ForCausalLM(\n",
       "      (model): Qwen2Model(\n",
       "        (embed_tokens): Embedding(152064, 3584, padding_idx=151654)\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2Attention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3584, out_features=3584, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3584, out_features=512, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3584, out_features=512, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3584, out_features=3584, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=18944, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "          )\n",
       "          (2-4): 3 x Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=18944, out_features=3584, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=18944, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "          )\n",
       "          (5-24): 20 x Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=18944, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "          )\n",
       "          (25-26): 2 x Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=18944, out_features=3584, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=18944, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "          )\n",
       "          (27): Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=18944, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = model_name,\n",
    "        max_seq_length = 8192,\n",
    "        dtype = None,\n",
    "        load_in_4bit = True,\n",
    "        )\n",
    "\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ada08b2-45de-42d6-9839-37576a9f97a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTER_TO_INDEX = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "\n",
    "class Example:\n",
    "    def __init__(self, question: str, choice1: str, choice2: str, choice3: str, choice4: str):\n",
    "        self.question = question\n",
    "        self.choice1 = choice1\n",
    "        self.choice2 = choice2\n",
    "        self.choice3 = choice3\n",
    "        self.choice4 = choice4\n",
    "\n",
    "    @property\n",
    "    def choices(self):\n",
    "        return [self.choice1, self.choice2, self.choice3, self.choice4]\n",
    "\n",
    "def _base_prompt() -> str:\n",
    "    return \"\"\"Act as an expert legal assistant with comprehensive knowledge of statutory law and case precedent. Analyze the following legal question carefully, then select the correct answer from the given options through rigorous legal reasoning.\"\"\"\n",
    "\n",
    "def _format_choices(options: list[str]) -> str:\n",
    "    return \"\\n\".join(f\"({chr(65 + i)}) {choice}\" for i, choice in enumerate(options))\n",
    "\n",
    "def _build_question_section(example: Example) -> str:\n",
    "    return f\"\\n\\nQuestion: {example.question}\\nChoices:\\n{_format_choices(example.choices)}\"\n",
    "\n",
    "def _build_instructions() -> str:\n",
    "    return \"\"\"\\n\\n\n",
    "        Instructions:\n",
    "        1. Conduct thorough legal analysis of all options\n",
    "        2. Consider relevant statutes, regulations, and judicial interpretations\n",
    "        3. Identify potential ambiguities or counterarguments\n",
    "        4. Select only the BEST supported answer\n",
    "        5. Respond SOLELY with the correct letter (A-D)\n",
    "\n",
    "        Answer using this format:\n",
    "        [X]\"\"\"\n",
    "\n",
    "def _build_final_instruction() -> str:\n",
    "    return \"\\n\\nPlease reply only with the correct option, do not say anything else.\"\n",
    "\n",
    "def _prepare_examples(example: Example, no: int = 5) -> str:\n",
    "    filtered_df = df[df['Question'] != example.question].sample(frac=1)\n",
    "    examples = []\n",
    "    \n",
    "    for _, row in filtered_df.head(no).iterrows():\n",
    "        right_answer = str(row['Answer'])\n",
    "        option = [right_answer]\n",
    "        \n",
    "        distractors = df[df['Answer'] != right_answer]['Answer'].astype(str).unique()\n",
    "        if len(distractors) < 3:\n",
    "            raise ValueError(\"Not enough unique distractors in the DataFrame.\")\n",
    "        option += random.sample(list(distractors), 3)\n",
    "        \n",
    "        random.shuffle(option)\n",
    "        correct_letter = chr(option.index(right_answer) + 65)\n",
    "        \n",
    "        example_str = (\n",
    "            f\"\\n\\nQuestion: {row['Question']}\"\n",
    "            f\"\\nChoices:\\n{_format_choices(option)}\"\n",
    "            f\"\\nThe correct answer is ({correct_letter})\"\n",
    "        )\n",
    "        examples.append(example_str)\n",
    "    \n",
    "    return \"--- START OF EXAMPLES ---\\n\" + \"\".join(examples) + \"\\n\\n--- END OF EXAMPLES ---\\n\"\n",
    "\n",
    "def chain_of_thought_prompt(example: Example, max_new_tokens: int = 256) -> str:\n",
    "    prompt = _base_prompt() + _build_question_section(example)\n",
    "    prompt += f\"\\n\\nLet's analyze this step by step. First, understand the question. Next, evaluate each option in short (2-5) lines each. Also, you can generate up to {max_new_tokens} tokens to reason.\"\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt},]\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=True,\n",
    "                add_generation_prompt=True,  # Must add for generation\n",
    "                return_tensors=\"pt\",).to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "                input_ids=inputs, \n",
    "                max_new_tokens=max_new_tokens, \n",
    "                use_cache=True, \n",
    "                temperature=1.5, \n",
    "                min_p=0.1)\n",
    "\n",
    "\n",
    "    # Extract generated text\n",
    "    cot_reasoning = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    prompt = f\"{cot_reasoning}\\n\\nBased on the above, reasoning what is the single, most likely answer choice? \\nAnswer using this format:\\n[X]\"\n",
    "    prompt += _build_final_instruction()\n",
    "    return prompt\n",
    "\n",
    "def five_shot_prompt(example: Example, no: int = 5) -> str:\n",
    "    prompt = _base_prompt()\n",
    "    prompt += \"\\nHere are some example questions from experts. Answer the final question yourself, following the format of the previous questions exactly.\\n\"\n",
    "    prompt += _prepare_examples(example=example, no=no)\n",
    "    prompt += \"\\n\\nNow your turn. Choose the correct option that answers the below question.\\n\"\n",
    "    prompt += _build_question_section(example)\n",
    "    prompt += _build_instructions()\n",
    "    prompt += _build_final_instruction()\n",
    "    return prompt\n",
    "\n",
    "def zero_shot_prompt(example: Example) -> str:\n",
    "    prompt = _base_prompt() + _build_question_section(example)\n",
    "    prompt += _build_instructions()\n",
    "    prompt += _build_final_instruction()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac83829c-ce8e-4c95-ad16-d2cdded0b954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed9272b0-b2f2-4c52-b547-e938920c44f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runner(n=1, prompt_type='zero_shot_prompt'):\n",
    "    for i in tqdm(range(n), desc=\"Iterations\"):\n",
    "        results = []\n",
    "        \n",
    "        # Precompute paths and create directory once per iteration\n",
    "        model_folder = model_name.split('/')[1]\n",
    "        output_dir = f\"../results/finetune_model_eval/{prompt_type}/{model_folder}/\"\n",
    "        output_file = os.path.join(output_dir, f\"output_{i}.json\")\n",
    "        os.makedirs(output_dir, exist_ok=True)  # Create directory if needed\n",
    "        \n",
    "        for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "            try:\n",
    "                question = row['Question']\n",
    "                right_answer = row['Answer']\n",
    "                # selecting distractions.\n",
    "                option = []\n",
    "                option.append(right_answer)\n",
    "                while len(option) < 4:\n",
    "                    distractor = df.sample(1)['Answer'].values[0]\n",
    "                    if distractor not in option and distractor != right_answer:\n",
    "                        option.append(distractor)\n",
    "\n",
    "                # Create an example\n",
    "                random.shuffle(option)\n",
    "                right_option_index = option.index(right_answer)\n",
    "                right_option_letter = chr(ord('A') + right_option_index)\n",
    "                \n",
    "                example = Example(question, \n",
    "                                  option[0], \n",
    "                                  option[1], \n",
    "                                  option[2], \n",
    "                                  option[3]\n",
    "                                )\n",
    "                \n",
    "                # Depending on prompt_type, generate the prompt using the integrated functions\n",
    "                if prompt_type == 'zero_shot_prompt':\n",
    "                    prompt = zero_shot_prompt(example)\n",
    "                elif prompt_type == 'five_shot_prompt':\n",
    "                    n_examples = 5\n",
    "                    prompt =  five_shot_prompt(example, n_examples)\n",
    "                elif prompt_type == 'chain_of_thought_prompt':\n",
    "                    thinking_tokens = 512\n",
    "                    prompt = chain_of_thought_prompt(example, thinking_tokens)\n",
    "                else:\n",
    "                    # Default behavior (original prompt)\n",
    "                    print(\"SELECTING DEFAULT PROMPTING TECHNIQUE\")\n",
    "                    prompt = zero_shot_prompt(example)\n",
    "\n",
    "                # Prepare Inputs\n",
    "                messages = [{\"role\": \"user\", \"content\": prompt},]\n",
    "                inputs = tokenizer.apply_chat_template(\n",
    "                            messages,\n",
    "                            tokenize=True,\n",
    "                            add_generation_prompt=True,  # Must add for generation\n",
    "                            return_tensors=\"pt\",).to(\"cuda\")\n",
    "                \n",
    "                # Generate outputs\n",
    "                outputs = model.generate(\n",
    "                            input_ids=inputs, \n",
    "                            max_new_tokens=15, # Restrict to 15 tokens so that we dont get garbage\n",
    "                            use_cache=True, \n",
    "                            temperature=1.5, \n",
    "                            min_p=0.1)\n",
    "\n",
    "\n",
    "                # Decode output\n",
    "                generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "                answer_portion = generated_text.split(\"do not say anything else.\")[1] # do not say anything else. : is the ending of our prompt\n",
    "                \n",
    "                match = re.search(r'[A-D]', answer_portion)\n",
    "                if match:\n",
    "                    model_answer_letter = match.group()\n",
    "                else:\n",
    "                    model_answer_letter = 'NA'\n",
    "                \n",
    "                if index == 0 and i==0:\n",
    "                    print(generated_text)\n",
    "                    print(\"Correct Ans: \", right_answer)\n",
    "                    print(\"Model Replied with: \", model_answer_letter)\n",
    "                    \n",
    "                is_correct = (right_option_letter and model_answer_letter) and right_option_letter.lower() == model_answer_letter.lower()\n",
    "                result = {\n",
    "                    \"iteration\": i,\n",
    "                    \"id\": index,\n",
    "                    \"model\": model_name,\n",
    "                    \"prompt_type\": prompt_type,\n",
    "                    \"prompt\": prompt,\n",
    "                    \"question\": question,\n",
    "                    \"right_answer\": right_answer,\n",
    "                    \"right_answer_option\": right_option_letter,\n",
    "                    \"model_answer_letter\": model_answer_letter,\n",
    "                    \"generated_text\": generated_text,\n",
    "                    \"answer_portion\": answer_portion,\n",
    "                    \"is_correct\": str(is_correct)\n",
    "                }\n",
    "                results.append(result)\n",
    "\n",
    "                # Save progress every 50 successful completions\n",
    "                if len(results) % 50 == 0:\n",
    "                    #print('saving')\n",
    "                    with open(output_file, 'w') as f:\n",
    "                        json.dump(results, f, indent=4)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {index}: {e}\")\n",
    "                continue \n",
    "\n",
    "        # Final save for remaining items after processing all rows\n",
    "        if len(results) > 0:\n",
    "            with open(output_file, 'w') as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "                \n",
    "        print(f\"Iteration {i} complete. Results saved to {output_file}\")\n",
    "        print(\"Evaluation complete. Results saved to output.json.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cd62c74-9d2c-470c-999c-c0c18a9ce9e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f0265240204eccb92e2cf506f4f278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c38adf6a9445d0b450f7f29a717322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\n",
      "user\n",
      "system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\n",
      "user\n",
      "Act as an expert legal assistant with comprehensive knowledge of statutory law and case precedent. Analyze the following legal question carefully, then select the correct answer from the given options through rigorous legal reasoning.\n",
      "\n",
      "Question: Is a high school diploma required for an F-1 visa?\n",
      "Choices:\n",
      "(A) The Designated School Official (DSO) at your Student and Exchange Visitor Program (SEVP)-certified school is responsible for approving an extension of your F-1 visa. However, the DSO can only grant an extension if you are maintaining your student status and have a valid reason for needing more time to complete your program. The DSO will update your SEVIS record to reflect the program extension.\n",
      "(B) To demonstrate the connection between your Curricular Practical Training (CPT) and your major, provide a comprehensive job description outlining your responsibilities and how they directly apply the knowledge, theories, and skills learned in your academic program. Emphasize the specific coursework or concepts from your major that are utilized in your CPT role, illustrating a clear and logical relationship between your studies and practical work experience. Strong documentation will increase the likelihood of CPT approval by designated school officials.\n",
      "(C) Immediately secure a signed sponsorship letter and current bank statements from the new sponsor, ensuring the funds are sufficient to cover your expenses. Notify the relevant international student office at your institution to request an updated I-20 reflecting the new financial support, as this is crucial for maintaining your student status and visa eligibility. Be prepared to explain the sudden change in sponsorship during your visa interview, providing documentation and demonstrating a clear understanding of your financial resources.\n",
      "(D) A high school diploma or its equivalent is generally required for an F-1 visa if you intend to pursue academic studies at a college, university, or other post-secondary institution. However, if you plan to enroll in a vocational or non-academic program, a high school diploma might not be mandatory, but meeting the educational requirements of that specific program is still essential. Always verify the specific admission requirements of the educational institution you plan to attend to ensure compliance with F-1 visa eligibility criteria.\n",
      "\n",
      "Let's analyze this step by step. First, understand the question. Next, evaluate each option in short (2-5) lines each. Also, you can generate up to 512 tokens to reason.\n",
      "assistant\n",
      "The correct answer is (D). A high school diploma or equivalent is generally required for an F-1 visa if you intend to pursue academic studies at a college, university, or other post-secondary institution. However, if you plan to enroll in a vocational or non-academic program, a high school diploma might not be mandatory, but meeting the educational requirements of that specific program is still essential. Always verify the specific admission requirements of the educational institution you plan to attend to ensure compliance with F-1 visa eligibility criteria. Options (A ), (B), and (C) address different aspects of F-1 visas, such as program extensions, CPT documentation, and financial support updates, which are not relevant to the question of whether a high school diploma is required.\n",
      "\n",
      "Based on the above, reasoning what is the single, most likely answer choice? \n",
      "Answer using this format:\n",
      "[X]\n",
      "\n",
      "Please reply only with the correct option, do not say anything else.\n",
      "assistant\n",
      "[D]\n",
      "Correct Ans:  A high school diploma or its equivalent is generally required for an F-1 visa if you intend to pursue academic studies at a college, university, or other post-secondary institution. However, if you plan to enroll in a vocational or non-academic program, a high school diploma might not be mandatory, but meeting the educational requirements of that specific program is still essential. Always verify the specific admission requirements of the educational institution you plan to attend to ensure compliance with F-1 visa eligibility criteria.\n",
      "Model Replied with:  D\n",
      "Iteration 0 complete. Results saved to ../results/finetune_model_eval/chain_of_thought_prompt/Qwen2.5-7B-Instruct-law-lora_model/output_0.json\n",
      "Evaluation complete. Results saved to output.json.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d6bf767ada492b932e7c0e206c902c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 complete. Results saved to ../results/finetune_model_eval/chain_of_thought_prompt/Qwen2.5-7B-Instruct-law-lora_model/output_1.json\n",
      "Evaluation complete. Results saved to output.json.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976b5382207544798886820a0d5a7ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 complete. Results saved to ../results/finetune_model_eval/chain_of_thought_prompt/Qwen2.5-7B-Instruct-law-lora_model/output_2.json\n",
      "Evaluation complete. Results saved to output.json.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910a334ce6a242d4af5d6ed8faefaf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3 complete. Results saved to ../results/finetune_model_eval/chain_of_thought_prompt/Qwen2.5-7B-Instruct-law-lora_model/output_3.json\n",
      "Evaluation complete. Results saved to output.json.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72742d428c7143ec97d9bab791269c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4 complete. Results saved to ../results/finetune_model_eval/chain_of_thought_prompt/Qwen2.5-7B-Instruct-law-lora_model/output_4.json\n",
      "Evaluation complete. Results saved to output.json.\n"
     ]
    }
   ],
   "source": [
    "runner(5, 'chain_of_thought_prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d668fe35-f5e0-412b-928f-3da0a7947aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ../results/finetune_model_eval/zero_shot_prompt/Qwen2.5-7B-Instruct-law-lora_model/output_1.json\n",
      "Total is_correct = True: 987\n",
      "Total is_correct = False: 13\n",
      "Total is_correct = NA: 0\n",
      "----------------------------------------\n",
      "File: ../results/finetune_model_eval/zero_shot_prompt/Qwen2.5-7B-Instruct-law-lora_model/output_4.json\n",
      "Total is_correct = True: 974\n",
      "Total is_correct = False: 26\n",
      "Total is_correct = NA: 0\n",
      "----------------------------------------\n",
      "File: ../results/finetune_model_eval/zero_shot_prompt/Qwen2.5-7B-Instruct-law-lora_model/output_3.json\n",
      "Total is_correct = True: 984\n",
      "Total is_correct = False: 16\n",
      "Total is_correct = NA: 0\n",
      "----------------------------------------\n",
      "File: ../results/finetune_model_eval/zero_shot_prompt/Qwen2.5-7B-Instruct-law-lora_model/output_2.json\n",
      "Total is_correct = True: 983\n",
      "Total is_correct = False: 17\n",
      "Total is_correct = NA: 0\n",
      "----------------------------------------\n",
      "File: ../results/finetune_model_eval/zero_shot_prompt/Qwen2.5-7B-Instruct-law-lora_model/output_0.json\n",
      "Total is_correct = True: 978\n",
      "Total is_correct = False: 22\n",
      "Total is_correct = NA: 0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "prompt_type = 'zero_shot_prompt' #\"chain_of_thought_prompt\"  # five_shot_prompt # zero_shot_prompt\n",
    "model_name =  \"Jenitza182/Qwen2.5-7B-Instruct-law-lora_model\"\n",
    "\n",
    "# Construct the directory path\n",
    "directory = f\"../results/finetune_model_eval/{prompt_type}/{model_name.split('/')[1]}/\" # When running on Jetstream\n",
    "#directory = f\"../results/finetune_model_eval/{prompt_type}/{model_name.split('/')[1]}/\" # When running in VS CODE\n",
    "\n",
    "# Find all JSON files matching output_*.json pattern\n",
    "json_files = glob.glob(os.path.join(directory, \"output_*.json\"))\n",
    "\n",
    "# Process each JSON file\n",
    "for file_path in json_files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Count occurrences of is_correct = True and is_correct = False\n",
    "    true_count = sum(1 for item in data if item.get(\"is_correct\") == 'True') # model answer == actual answer\n",
    "    false_count = sum(1 for item in data if item.get(\"is_correct\") == 'False') # model answer != actual answer\n",
    "    na_count = sum(1 for item in data if item.get(\"is_correct\") == 'NA') # Model was not able to answer/ Answer not found in response\n",
    "    \n",
    "    print(f\"File: {file_path}\")\n",
    "    print(f\"Total is_correct = True: {true_count}\")\n",
    "    print(f\"Total is_correct = False: {false_count}\")\n",
    "    print(f\"Total is_correct = NA: {na_count}\")\n",
    "    print(\"-\" * 40) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67229fc7-7192-48a2-9054-1b743aa0628b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
