{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenitza/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LETTER_TO_INDEX = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "\n",
    "class Example:\n",
    "    def __init__(self, question: str, choice1: str, choice2: str, choice3: str, choice4: str):\n",
    "        self.question = question\n",
    "        self.choice1 = choice1\n",
    "        self.choice2 = choice2\n",
    "        self.choice3 = choice3\n",
    "        self.choice4 = choice4\n",
    "\n",
    "# def _load_from_json(path: str) -> Dict:\n",
    "#     \"\"\"Load json from a file.\"\"\"\n",
    "#     with open(path, 'r') as f:\n",
    "#         return json.load(f)\n",
    "\n",
    "def _base_prompt(example: Example) -> str:\n",
    "    \"\"\"Creates a zero-shot prompt given a single example. Uses the prompt format from this paper on Scalable Oversight:\n",
    "    https://arxiv.org/abs/2211.03540\"\"\"\n",
    "    #prompt = f\"What is the correct answer to this question: {example.question}\"\n",
    "    prompt = f\"\"\"You are a smart law assistant. You are given a question and four possible answers. Your task is to choose the most likely answer and respond with only the option letter (A, B, C, D): \\nQuestion: {example.question}\"\"\"\n",
    "    prompt += f\"\\n\\nChoices:\\n(A) {example.choice1}\\n(B) {example.choice2}\\n(C) {example.choice3}\\n(D) {example.choice4}\"\n",
    "    return prompt\n",
    "\n",
    "# def _generate_prompt_from_examples(json_data, with_explanations=True):\n",
    "#     output = \"\"\n",
    "#     for q in json_data[\"questions\"]:\n",
    "#         output += f'\\nQuestion: {q[\"question\"]}\\nChoices:\\n'\n",
    "#         for choice, value in q[\"choices\"].items():\n",
    "#             output += f'({choice}) {value}\\n'\n",
    "\n",
    "#         if with_explanations:\n",
    "#             output += f\"Let's think step by step: \\n{q['explanation']}\\n\"\n",
    "#         output += f'The correct answer is ({q[\"correct_answer\"]})\\n'\n",
    "#     return output\n",
    "\n",
    "def zero_shot_chain_of_thought_prompt(example: Example, pipe) -> str: # no reasoning\n",
    "    # \"\"\"Creates a chain-of-thought prompt given a single example.\"\"\"\n",
    "    prompt = _base_prompt(example)\n",
    "    prompt += \"\\nLet's think step by step: \"\n",
    "    cot_output = pipe(\n",
    "                example.question,\n",
    "                max_new_tokens=256,\n",
    "                pad_token_id=pipe.tokenizer.eos_token_id,\n",
    "                num_beams=5,\n",
    "                early_stopping=True,\n",
    "                eos_token_id=pipe.tokenizer.eos_token_id\n",
    "            )\n",
    "    cot_reasoning = cot_output[0]['generated_text']\n",
    "    prompt += f\"{cot_reasoning}\\n\\nBased on the above, what is the single, most likely answer choice? \\\n",
    "                Answer in the format \\\"The correct answer is (insert answer here)\\\".\"\n",
    "    return prompt\n",
    "\n",
    "# def chain_of_thought_prompt(example: Example) -> str: # with reasoning 5 examples\n",
    "#     \"\"\"Creates a chain-of-thought prompt given a single example.\"\"\"\n",
    "#     prompt = f\"Here are some example questions from experts. An explanation is given before the final answer. Answer the final question yourself, giving your reasoning beforehand.\\n\"\n",
    "#     json_data = _load_from_json(\"chain_of_thought_examples.json\")\n",
    "#     prompt += _generate_prompt_from_examples(json_data, with_explanations=True)\n",
    "#     prompt += \"\\nNow your turn.\\n\"\n",
    "#     prompt += f\"Question: {example.question}\"\n",
    "#     prompt += f\"\\nChoices:\\n(A) {example.choice1}\\n(B) {example.choice2}\\n(C) {example.choice3}\\n(D) {example.choice4}\"\n",
    "#     prompt += \"\\nGive step by step reasoning before you answer, and when you're ready to answer, please use the format \\\"The correct answer is (insert answer here)\\\":\\n\"\n",
    "#     return prompt\n",
    "\n",
    "# def five_shot_prompt(example: Example) -> str: #with 5 examples # withput reasoning\n",
    "#     \"\"\"Creates a chain-of-thought prompt given a single example.\"\"\"\n",
    "#     prompt = f\"Here are some example questions from experts. Answer the final question yourself, following the format of the previous questions exactly.\\n\"\n",
    "#     json_data = _load_from_json(\"chain_of_thought_examples.json\")\n",
    "#     prompt += _generate_prompt_from_examples(json_data, with_explanations=False)\n",
    "\n",
    "#     prompt += f\"Question: {example.question}\"\n",
    "#     prompt += f\"\\nChoices:\\n(A) {example.choice1}\\n(B) {example.choice2}\\n(C) {example.choice3}\\n(D) {example.choice4}\"\n",
    "#     prompt += \"\\nWhen you're ready to answer, please use the format \\\"The correct answer is (insert answer here).\"\n",
    "#     return prompt\n",
    "\n",
    "def zero_shot_prompt(example: Example) -> str: # just the question and the choices\n",
    "    \"\"\"Creates a zero-shot prompt given a single example.\"\"\"\n",
    "    prompt = _base_prompt(example)\n",
    "    prompt += f\"\\n\\nPlease reply only with the correct option, do not say anything else.\\\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do I apply for CPT?</td>\n",
       "      <td>You must get approval from your Designated Sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What documents are required for CPT?</td>\n",
       "      <td>Typically you need:\\n- CPT Request Form from y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How long does CPT processing take?</td>\n",
       "      <td>Processing usually takes 5-10 business days af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can I work before receiving CPT authorization?</td>\n",
       "      <td>No you must wait for approval and receive an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do I need to pay any fees for CPT?</td>\n",
       "      <td>No CPT does not require a separate application...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Question  \\\n",
       "0                         How do I apply for CPT?   \n",
       "1            What documents are required for CPT?   \n",
       "2              How long does CPT processing take?   \n",
       "3  Can I work before receiving CPT authorization?   \n",
       "4              Do I need to pay any fees for CPT?   \n",
       "\n",
       "                                              Answer  \n",
       "0  You must get approval from your Designated Sch...  \n",
       "1  Typically you need:\\n- CPT Request Form from y...  \n",
       "2  Processing usually takes 5-10 business days af...  \n",
       "3  No you must wait for approval and receive an u...  \n",
       "4  No CPT does not require a separate application...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataset/cleaned_dataset.csv\", encoding=\"utf-8\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # delete empty rows\n",
    "# df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove ',' from df[Answer]\n",
    "# df['Answer'] = df['Answer'].str.replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"../dataset/cleaned_dataset.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model pipeline\n",
    "#pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-1B-Instruct\", device='cuda')\n",
    "\n",
    "\n",
    "def runner(n=1, prompt_type='zero_shot_prompt'):\n",
    "   # model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "    for i in tqdm(range(n), desc=\"Iterations\"):\n",
    "        results = []\n",
    "        for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "            try:\n",
    "                question = row['Question'].strip()\n",
    "                right_answer = row['Answer'].strip()\n",
    "                # selecting distractions.\n",
    "                option = []\n",
    "                option.append(right_answer)\n",
    "                while len(option) < 4:\n",
    "                    distractor = df.sample(1)['Answer'].values[0].strip()\n",
    "                    if distractor not in option and distractor != right_answer:\n",
    "                        option.append(distractor)\n",
    "\n",
    "                # print(f\"Question: {question}\")\n",
    "                # print(f\"Right Answer: {right_answer}\")\n",
    "                # print(f\"Options: {option}\")\n",
    "                # print(len(option)) \n",
    "                # break\n",
    "\n",
    "                # Create an example\n",
    "                random.shuffle(option)\n",
    "                example = Example(question, \n",
    "                                  option[0], \n",
    "                                  option[1], \n",
    "                                  option[2], \n",
    "                                  option[3]\n",
    "                                )\n",
    "                \n",
    "\n",
    "                # Depending on prompt_type, generate the prompt using the integrated functions\n",
    "                if prompt_type == 'zero_shot_prompt':\n",
    "                    prompt = zero_shot_prompt(example)\n",
    "                # elif prompt_type == 'chain_of_thought_prompt':\n",
    "                #     prompt = chain_of_thought_prompt(example)\n",
    "                # elif prompt_type == 'five_shot_prompt':\n",
    "                #     prompt = five_shot_prompt(example)\n",
    "                elif prompt_type == 'zero_shot_chain_of_thought':\n",
    "                    pass\n",
    "                   # prompt = zero_shot_chain_of_thought_prompt(example, pipe)\n",
    "                else:\n",
    "                    # Default behavior (original prompt)\n",
    "                    prompt = zero_shot_prompt(example)\n",
    "                    \n",
    "                if index == 0:\n",
    "                    print(prompt)\n",
    "                    print(\"Correct Ans: \", right_answer)\n",
    "                    break\n",
    "\n",
    "                # Generate the model's response\n",
    "                # response = pipe(\n",
    "                #     prompt,\n",
    "                #     max_new_tokens=256,\n",
    "                #     pad_token_id=pipe.tokenizer.eos_token_id,\n",
    "                #     num_beams=5,\n",
    "                #     early_stopping=True,\n",
    "                #     eos_token_id=pipe.tokenizer.eos_token_id\n",
    "                # )\n",
    "\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {index}: {e}\")\n",
    "                continue    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   0%|          | 0/131 [00:00<?, ?it/s]\n",
      "Iterations: 100%|██████████| 1/1 [00:00<00:00, 212.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a smart law assistant. You are given a question and four possible answers. Your task is to choose the most likely answer and respond with only the option letter (A, B, C, D): \n",
      "Question: How do I apply for CPT?\n",
      "\n",
      "Choices:\n",
      "(A) No STEM OPT requires paid employment with an E-Verify employer.\n",
      "(B) You must get approval from your Designated School Official (DSO) and submit a CPT request form along with an offer letter from your employer.\n",
      "(C) Yes but all jobs must be related to your field of study.\n",
      "(D) Processing usually takes 5-10 business days after submission to the DSO.\n",
      "\n",
      "Please reply only with the correct option, do not say anything else.\"\n",
      "Correct Ans:  You must get approval from your Designated School Official (DSO) and submit a CPT request form along with an offer letter from your employer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "runner(1, 'zero_shot_prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do I apply for CPT?</td>\n",
       "      <td>You must get approval from your Designated Sch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Question                                             Answer\n",
       "0  How do I apply for CPT?  You must get approval from your Designated Sch..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
