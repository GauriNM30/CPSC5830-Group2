{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenitza/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import pipeline\n",
    "from typing import Dict\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jenitza/anaconda3/bin/huggingface-cli\", line 11, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/Users/jenitza/anaconda3/lib/python3.11/site-packages/huggingface_hub/commands/huggingface_cli.py\", line 49, in main\n",
      "    service.run()\n",
      "  File \"/Users/jenitza/anaconda3/lib/python3.11/site-packages/huggingface_hub/commands/user.py\", line 101, in run\n",
      "    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)\n",
      "  File \"/Users/jenitza/anaconda3/lib/python3.11/site-packages/huggingface_hub/_login.py\", line 96, in login\n",
      "    _login(token, add_to_git_credential=add_to_git_credential, write_permission=write_permission)\n",
      "  File \"/Users/jenitza/anaconda3/lib/python3.11/site-packages/huggingface_hub/_login.py\", line 275, in _login\n",
      "    raise ValueError(\"Invalid token passed!\")\n",
      "ValueError: Invalid token passed!\n"
     ]
    }
   ],
   "source": [
    "HUGGINGFACE_API_KEY = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "!huggingface-cli login --token HUGGINGFACE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do I apply for CPT?</td>\n",
       "      <td>You must get approval from your Designated Sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What documents are required for CPT?</td>\n",
       "      <td>Typically you need:\\n- CPT Request Form from y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How long does CPT processing take?</td>\n",
       "      <td>Processing usually takes 5-10 business days af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can I work before receiving CPT authorization?</td>\n",
       "      <td>No you must wait for approval and receive an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do I need to pay any fees for CPT?</td>\n",
       "      <td>No CPT does not require a separate application...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Question  \\\n",
       "0                         How do I apply for CPT?   \n",
       "1            What documents are required for CPT?   \n",
       "2              How long does CPT processing take?   \n",
       "3  Can I work before receiving CPT authorization?   \n",
       "4              Do I need to pay any fees for CPT?   \n",
       "\n",
       "                                              Answer  \n",
       "0  You must get approval from your Designated Sch...  \n",
       "1  Typically you need:\\n- CPT Request Form from y...  \n",
       "2  Processing usually takes 5-10 business days af...  \n",
       "3  No you must wait for approval and receive an u...  \n",
       "4  No CPT does not require a separate application...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/cleaned_dataset.csv\", encoding=\"utf-8\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTER_TO_INDEX = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "\n",
    "class Example:\n",
    "    def __init__(self, question: str, choice1: str, choice2: str, choice3: str, choice4: str):\n",
    "        self.question = question\n",
    "        self.choice1 = choice1\n",
    "        self.choice2 = choice2\n",
    "        self.choice3 = choice3\n",
    "        self.choice4 = choice4\n",
    "\n",
    "    @property\n",
    "    def choices(self):\n",
    "        return [self.choice1, self.choice2, self.choice3, self.choice4]\n",
    "\n",
    "def _base_prompt() -> str:\n",
    "    return \"\"\"Act as an expert legal assistant with comprehensive knowledge of statutory law and case precedent. Analyze the following legal question carefully, then select the correct answer from the given options through rigorous legal reasoning.\"\"\"\n",
    "\n",
    "def _format_choices(options: list[str]) -> str:\n",
    "    return \"\\n\".join(f\"({chr(65 + i)}) {choice}\" for i, choice in enumerate(options))\n",
    "\n",
    "def _build_question_section(example: Example) -> str:\n",
    "    return f\"\\n\\nQuestion: {example.question}\\nChoices:\\n{_format_choices(example.choices)}\"\n",
    "\n",
    "def _build_instructions() -> str:\n",
    "    return \"\"\"\\n\\n\n",
    "        Instructions:\n",
    "        1. Conduct thorough legal analysis of all options\n",
    "        2. Consider relevant statutes, regulations, and judicial interpretations\n",
    "        3. Identify potential ambiguities or counterarguments\n",
    "        4. Select only the BEST supported answer\n",
    "        5. Respond SOLELY with the correct letter (A-D)\n",
    "\n",
    "        Answer using this format:\n",
    "        [X]\"\"\"\n",
    "\n",
    "def _build_final_instruction() -> str:\n",
    "    return \"\\n\\nPlease reply only with the correct option, do not say anything else.\\\"\"\n",
    "\n",
    "def _prepare_examples(example: Example, no: int = 5) -> str:\n",
    "    filtered_df = df[df['Question'] != example.question].sample(frac=1)\n",
    "    examples = []\n",
    "    \n",
    "    for _, row in filtered_df.head(no).iterrows():\n",
    "        right_answer = str(row['Answer'])\n",
    "        option = [right_answer]\n",
    "        \n",
    "        distractors = df[df['Answer'] != right_answer]['Answer'].astype(str).unique()\n",
    "        if len(distractors) < 3:\n",
    "            raise ValueError(\"Not enough unique distractors in the DataFrame.\")\n",
    "        option += random.sample(list(distractors), 3)\n",
    "        \n",
    "        random.shuffle(option)\n",
    "        correct_letter = chr(option.index(right_answer) + 65)\n",
    "        \n",
    "        example_str = (\n",
    "            f\"\\n\\nQuestion: {row['Question']}\"\n",
    "            f\"\\nChoices:\\n{_format_choices(option)}\"\n",
    "            f\"\\nThe correct answer is ({correct_letter})\"\n",
    "        )\n",
    "        examples.append(example_str)\n",
    "    \n",
    "    return \"--- START OF EXAMPLES ---\\n\" + \"\".join(examples) + \"\\n\\n--- END OF EXAMPLES ---\\n\"\n",
    "\n",
    "def chain_of_thought_prompt(example: Example, max_new_tokens: int = 256) -> str:\n",
    "    prompt = _base_prompt() + _build_question_section(example)\n",
    "    prompt += f\"\\n\\nLet's analyze this step by step. First, understand the question. Next, evaluate each option in short (2-5) lines each. Also, you can generate up to {max_new_tokens} tokens to reason.\"\n",
    "\n",
    "    cot_output = pipe(\n",
    "        prompt,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        pad_token_id=pipe.tokenizer.eos_token_id,\n",
    "        num_beams=5,\n",
    "        early_stopping=True,\n",
    "        eos_token_id=pipe.tokenizer.eos_token_id,\n",
    "        temperature=0.5\n",
    "    )\n",
    "    cot_reasoning = cot_output[0]['generated_text']\n",
    "    prompt = f\"{cot_reasoning}\\n\\nBased on the above, reasoning what is the single, most likely answer choice? \\nAnswer using this format:\\n[X]\"\n",
    "    prompt += _build_final_instruction()\n",
    "    return prompt\n",
    "\n",
    "def five_shot_prompt(example: Example, no: int = 5) -> str:\n",
    "    prompt = _base_prompt()\n",
    "    prompt += \"\\nHere are some example questions from experts. Answer the final question yourself, following the format of the previous questions exactly.\\n\"\n",
    "    prompt += _prepare_examples(example=example, no=no)\n",
    "    prompt += \"\\n\\nNow your turn. Choose the correct option that answers the below question.\\n\"\n",
    "    prompt += _build_question_section(example)\n",
    "    prompt += _build_instructions()\n",
    "    prompt += _build_final_instruction()\n",
    "    return prompt\n",
    "\n",
    "def zero_shot_prompt(example: Example) -> str:\n",
    "    prompt = _base_prompt() + _build_question_section(example)\n",
    "    prompt += _build_instructions()\n",
    "    prompt += _build_final_instruction()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # delete empty rows\n",
    "# df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove ',' from df[Answer]\n",
    "# df['Answer'] = df['Answer'].str.replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c62d4d8ff9c4a24b5c42290afb40fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b5520e7d4d48018625bd070245e469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963289f49c704bf885ce891304e02491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2130d804b44d9c87000b8825a50f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f61451402c4022a2f1d0471d249ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5267c8074c2b45b19aa2ffbb7445c9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ac57d6f0364a93b4217788ec67b65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12411d56eba468c9d086b6856375a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b492b56437493f84ce068cf221daa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f85698c5c64911a5830f54bd310260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32be8a3c305b4a019dcab50c312261cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63a42b5979a46a98a537a7723dbd5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "# df.to_csv(\"../dataset/cleaned_dataset.csv\", index=False, encoding=\"utf-8\")\n",
    "model_name =  \"meta-llama/Llama-3.1-8B-Instruct\"# \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "pipe = pipeline (\"text-generation\", model=model_name, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model pipeline\n",
    "#pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-1B-Instruct\", device='cuda')\n",
    "\n",
    "def runner(n=1, prompt_type='zero_shot_prompt'):\n",
    "   # model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "    for i in tqdm(range(n), desc=\"Iterations\"):\n",
    "        results = []\n",
    "        for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "            try:\n",
    "                question = row['Question']\n",
    "                right_answer = row['Answer']\n",
    "                # selecting distractions.\n",
    "                option = []\n",
    "                option.append(right_answer)\n",
    "                while len(option) < 4:\n",
    "                    distractor = df.sample(1)['Answer'].values[0]\n",
    "                    if distractor not in option and distractor != right_answer:\n",
    "                        option.append(distractor)\n",
    "\n",
    "                # print(f\"Question: {question}\")\n",
    "                # print(f\"Right Answer: {right_answer}\")\n",
    "                # print(f\"Options: {option}\")\n",
    "                # print(len(option)) \n",
    "                # break\n",
    "\n",
    "                # Create an example\n",
    "                random.shuffle(option)\n",
    "                # Right option is \n",
    "                right_option_index = option.index(right_answer)\n",
    "                right_option_letter = chr(ord('A') + right_option_index)\n",
    "                #print(f\"\\n\\nRight option index: {right_option_letter}\")\n",
    "                \n",
    "                example = Example(question, \n",
    "                                  option[0], \n",
    "                                  option[1], \n",
    "                                  option[2], \n",
    "                                  option[3]\n",
    "                                )\n",
    "                \n",
    "                # Depending on prompt_type, generate the prompt using the integrated functions\n",
    "                if prompt_type == 'zero_shot_prompt':\n",
    "                    prompt = zero_shot_prompt(example)\n",
    "                elif prompt_type == 'five_shot_prompt':\n",
    "                    n_examples = 5\n",
    "                    prompt =  five_shot_prompt(example, n_examples)\n",
    "                elif prompt_type == 'chain_of_thought_prompt':\n",
    "                    thinking_tokens = 512\n",
    "                    prompt = chain_of_thought_prompt(example, thinking_tokens)\n",
    "                else:\n",
    "                    # Default behavior (original prompt)\n",
    "                    print(\"SELECTING DEFAULT PROMPTING TECHNIQUE\")\n",
    "                    prompt = zero_shot_prompt(example)\n",
    "\n",
    "                #print(prompt)\n",
    "                #break\n",
    "                # Generate the model's response\n",
    "                response = pipe(\n",
    "                    prompt,\n",
    "                    max_new_tokens=15,\n",
    "                    pad_token_id=pipe.tokenizer.eos_token_id,\n",
    "                    num_beams=5,\n",
    "                    early_stopping=True,\n",
    "                    eos_token_id=pipe.tokenizer.eos_token_id,\n",
    "                    temperature=0.1\n",
    "                )\n",
    "\n",
    "                # Extract generated text\n",
    "                generated_text = response[0][\"generated_text\"]\n",
    "                #print(generated_text)\n",
    "                answer_portion = generated_text.split(\"else.\")[1]\n",
    "                match = re.search(r'[A-D]', answer_portion)\n",
    "                if match:\n",
    "                    model_answer_letter = match.group()\n",
    "                else:\n",
    "                    model_answer_letter = 'NA'\n",
    "                \n",
    "                                \n",
    "                if index == 0 and i==0:\n",
    "                    print(prompt)\n",
    "                    print(\"Correct Ans: \", right_answer)\n",
    "                    print(\"Model Replied with: \", model_answer_letter)\n",
    "                    \n",
    "                is_correct = (right_option_letter and model_answer_letter) and right_option_letter.lower() == model_answer_letter.lower()\n",
    "\n",
    "                result = {\n",
    "                    \"iteration\": i,\n",
    "                    \"id\": index,\n",
    "                    \"model\": model_name,\n",
    "                    \"prompt_type\": prompt_type,\n",
    "                    \"question\": question,\n",
    "                    \"right_answer\": right_answer,\n",
    "                    \"right_answer_option\": right_option_letter,\n",
    "                    \"model_answer_letter\": model_answer_letter,\n",
    "                    \"generated_text\": generated_text,\n",
    "                    \"is_correct\": str(is_correct)\n",
    "                }\n",
    "                results.append(result)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {index}: {e}\")\n",
    "                print(generated_text)\n",
    "                continue \n",
    "\n",
    "        # Save the results\n",
    "        if not os.path.exists(f\"results/{prompt_type}/{model_name.split('/')[1]}\"):\n",
    "            os.makedirs(f\"results/{prompt_type}/{model_name.split('/')[1]}\")\n",
    "\n",
    "        with open(f\"results/{prompt_type}/{model_name.split('/')[1]}/output_{i}.json\", \"w\") as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "    \n",
    "        print(\"Evaluation complete. Results saved to output.json.\")    \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e9d22ab29e49a1b94485432dd00669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110b7c5992e14f80b49b3bf5a7bb539a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Act as an expert legal assistant with comprehensive knowledge of statutory law and case precedent. Analyze the following legal question carefully, then select the correct answer from the given options through rigorous legal reasoning.\n",
      "\n",
      "Question: How do I apply for CPT?\n",
      "Choices:\n",
      "(A) To file Form I-765 online:\n",
      "\n",
      " Create a USCIS online account if you don't already have one.\n",
      "\n",
      " Select 'File a Form Online.'\n",
      "\n",
      " Complete all sections of the form upload required evidence and pay the applicable fee.\n",
      "(B) You must get approval from your Designated School Official (DSO) and submit a CPT request form along with an offer letter from your employer.\n",
      "(C) Yes your employer can file an H-1B petition for you while you are on OPT or STEM OPT. If approved you may qualify for Cap-Gap Extension allowing you to work until H-1B status begins.\n",
      "(D) Generally CPT and OPT require U.S.-based employment. Remote work may be allowed if the employer has a U.S. presence and follows employment regulations.\n",
      "\n",
      "Let's analyze this step by step. First, understand the question. Next, evaluate each option in short (2-5) lines each. Also, you can generate up to 512 tokens to reason. \n",
      "\n",
      "Step 1: Understand the question\n",
      "The question is asking how to apply for CPT (Curricular Practical Training), which is a type of work authorization for international students in the United States.\n",
      "\n",
      "Step 2: Evaluate Option A\n",
      "Option A discusses filing Form I-765 online, which is actually the form for applying for an Employment Authorization Document (EAD), not CPT. So, this option is incorrect.\n",
      "\n",
      "Step 3: Evaluate Option B\n",
      "Option B mentions getting approval from a Designated School Official (DSO) and submitting a CPT request form along with an offer letter from an employer. This is the correct process for applying for CPT, as students must obtain approval from their DSO and have a job offer to apply for CPT.\n",
      "\n",
      "Step 4: Evaluate Option C\n",
      "Option C talks about an employer filing an H-1B petition while the student is on OPT (Optional Practical Training) or STEM OPT, which is unrelated to applying for CPT. So, this option is incorrect.\n",
      "\n",
      "Step 5: Evaluate Option D\n",
      "Option D mentions that CPT and OPT generally require U.S.-based employment and that remote work may be allowed if the employer has a U.S. presence and follows employment regulations. While this statement is true, it does not answer the question of how to apply for CPT.\n",
      "\n",
      "Step 6: Select the correct answer\n",
      "Based on the analysis, the correct answer is Option B, as it accurately describes the process for applying for CPT.\n",
      "\n",
      "The final answer is: $\\boxed{B}$ \n",
      "Note: The final answer is in the format specified, which is the letter of the correct option. \n",
      "The final answer is: $\\boxed{B}$ \n",
      "Note: The final answer is in the format specified, which is the letter of the correct option. \n",
      "The final answer is: $\\boxed{B}$ \n",
      "Note: The final answer is in the format specified, which is the letter of the correct option. \n",
      "The final answer is: $\\boxed{B}$ \n",
      "Note: The final answer is in the format specified, which is the letter of the correct option. \n",
      "The final answer is: $\\boxed{B}$ \n",
      "Note: The final answer is in the format specified, which is the letter of the correct option. \n",
      "The final answer is: $\\boxed{B}$ \n",
      "Note: The final answer is in the format specified, which is the letter of the correct option. \n",
      "The final answer is: $\\boxed{B}$ \n",
      "Note: The final answer\n",
      "\n",
      "Based on the above, reasoning what is the single, most likely answer choice? \n",
      "Answer using this format:\n",
      "[X]\n",
      "\n",
      "Please reply only with the correct option, do not say anything else.\"\n",
      "Correct Ans:  You must get approval from your Designated School Official (DSO) and submit a CPT request form along with an offer letter from your employer.\n",
      "Model Replied with:  B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "runner(5, 'chain_of_thought_prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ../results/five_shot_prompt/deepseek-llm-7b-chat/output_1.json\n",
      "Total is_correct = True: 73\n",
      "Total is_correct = False: 58\n",
      "----------------------------------------\n",
      "File: ../results/five_shot_prompt/deepseek-llm-7b-chat/output_0.json\n",
      "Total is_correct = True: 67\n",
      "Total is_correct = False: 64\n",
      "----------------------------------------\n",
      "File: ../results/five_shot_prompt/deepseek-llm-7b-chat/output_4.json\n",
      "Total is_correct = True: 68\n",
      "Total is_correct = False: 63\n",
      "----------------------------------------\n",
      "File: ../results/five_shot_prompt/deepseek-llm-7b-chat/output_3.json\n",
      "Total is_correct = True: 74\n",
      "Total is_correct = False: 57\n",
      "----------------------------------------\n",
      "File: ../results/five_shot_prompt/deepseek-llm-7b-chat/output_2.json\n",
      "Total is_correct = True: 67\n",
      "Total is_correct = False: 64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "prompt_type = 'five_shot_prompt' #\"zero_shot_prompt\" # 'five_shot_prompt', 'chain_of_thought_prompt'\n",
    "#model_name = 'meta-llama/Llama-3.2-3B-Instruct'\n",
    "model_name = \"deepseek-ai/deepseek-llm-7b-chat\" \n",
    "#model_name =  \"meta-llama/Llama-3.1-8B-Instruct\" # \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# Construct the directory path\n",
    "directory = f\"../results/{prompt_type}/{model_name.split('/')[1]}/\"\n",
    "\n",
    "# Find all JSON files matching output_*.json pattern\n",
    "json_files = glob.glob(os.path.join(directory, \"output_*.json\"))\n",
    "\n",
    "# Process each JSON file\n",
    "for file_path in json_files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Count occurrences of is_correct = True and is_correct = False\n",
    "    true_count = sum(1 for item in data if item.get(\"is_correct\") == 'True')\n",
    "    false_count = sum(1 for item in data if item.get(\"is_correct\") == 'False')\n",
    "                   \n",
    "    print(f\"File: {file_path}\")\n",
    "    print(f\"Total is_correct = True: {true_count}\")\n",
    "    print(f\"Total is_correct = False: {false_count}\")\n",
    "    print(\"-\" * 40) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
