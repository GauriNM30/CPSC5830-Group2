{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenitza/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import pipeline\n",
    "from typing import Dict\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HUGGINGFACE_API_KEY = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "# !huggingface-cli login --token HUGGINGFACE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do I apply for CPT?</td>\n",
       "      <td>You must get approval from your Designated Sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What documents are required for CPT?</td>\n",
       "      <td>Typically you need:\\n- CPT Request Form from y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How long does CPT processing take?</td>\n",
       "      <td>Processing usually takes 5-10 business days af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can I work before receiving CPT authorization?</td>\n",
       "      <td>No you must wait for approval and receive an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do I need to pay any fees for CPT?</td>\n",
       "      <td>No CPT does not require a separate application...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Question  \\\n",
       "0                         How do I apply for CPT?   \n",
       "1            What documents are required for CPT?   \n",
       "2              How long does CPT processing take?   \n",
       "3  Can I work before receiving CPT authorization?   \n",
       "4              Do I need to pay any fees for CPT?   \n",
       "\n",
       "                                              Answer  \n",
       "0  You must get approval from your Designated Sch...  \n",
       "1  Typically you need:\\n- CPT Request Form from y...  \n",
       "2  Processing usually takes 5-10 business days af...  \n",
       "3  No you must wait for approval and receive an u...  \n",
       "4  No CPT does not require a separate application...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../dataset/cleaned_dataset.csv\", encoding=\"utf-8\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTER_TO_INDEX = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "\n",
    "class Example:\n",
    "    def __init__(self, question: str, choice1: str, choice2: str, choice3: str, choice4: str):\n",
    "        self.question = question\n",
    "        self.choice1 = choice1\n",
    "        self.choice2 = choice2\n",
    "        self.choice3 = choice3\n",
    "        self.choice4 = choice4\n",
    "\n",
    "    @property\n",
    "    def choices(self):\n",
    "        return [self.choice1, self.choice2, self.choice3, self.choice4]\n",
    "\n",
    "def _base_prompt() -> str:\n",
    "    return \"\"\"Act as an expert legal assistant with comprehensive knowledge of statutory law and case precedent. Analyze the following legal question carefully, then select the correct answer from the given options through rigorous legal reasoning.\"\"\"\n",
    "\n",
    "def _format_choices(options: list[str]) -> str:\n",
    "    return \"\\n\".join(f\"({chr(65 + i)}) {choice}\" for i, choice in enumerate(options))\n",
    "\n",
    "def _build_question_section(example: Example) -> str:\n",
    "    return f\"\\n\\nQuestion: {example.question}\\nChoices:\\n{_format_choices(example.choices)}\"\n",
    "\n",
    "def _build_instructions() -> str:\n",
    "    return \"\"\"\\n\\n\n",
    "        Instructions:\n",
    "        1. Conduct thorough legal analysis of all options\n",
    "        2. Consider relevant statutes, regulations, and judicial interpretations\n",
    "        3. Identify potential ambiguities or counterarguments\n",
    "        4. Select only the BEST supported answer\n",
    "        5. Respond SOLELY with the correct letter (A-D)\n",
    "\n",
    "        Answer using this format:\n",
    "        [X]\"\"\"\n",
    "\n",
    "def _build_final_instruction() -> str:\n",
    "    return \"\\n\\nPlease reply only with the correct option, do not say anything else.\\\"\"\n",
    "\n",
    "def _prepare_examples(example: Example, no: int = 5) -> str:\n",
    "    filtered_df = df[df['Question'] != example.question].sample(frac=1)\n",
    "    examples = []\n",
    "    \n",
    "    for _, row in filtered_df.head(no).iterrows():\n",
    "        right_answer = str(row['Answer'])\n",
    "        option = [right_answer]\n",
    "        \n",
    "        distractors = df[df['Answer'] != right_answer]['Answer'].astype(str).unique()\n",
    "        if len(distractors) < 3:\n",
    "            raise ValueError(\"Not enough unique distractors in the DataFrame.\")\n",
    "        option += random.sample(list(distractors), 3)\n",
    "        \n",
    "        random.shuffle(option)\n",
    "        correct_letter = chr(option.index(right_answer) + 65)\n",
    "        \n",
    "        example_str = (\n",
    "            f\"\\n\\nQuestion: {row['Question']}\"\n",
    "            f\"\\nChoices:\\n{_format_choices(option)}\"\n",
    "            f\"\\nThe correct answer is ({correct_letter})\"\n",
    "        )\n",
    "        examples.append(example_str)\n",
    "    \n",
    "    return \"--- START OF EXAMPLES ---\\n\" + \"\".join(examples) + \"\\n\\n--- END OF EXAMPLES ---\\n\"\n",
    "\n",
    "def chain_of_thought_prompt(example: Example, max_new_tokens: int = 256) -> str:\n",
    "    prompt = _base_prompt() + _build_question_section(example)\n",
    "    prompt += f\"\\n\\nLet's analyze this step by step. First, understand the question. Next, evaluate each option in short (2-5) lines each. Also, you can generate up to {max_new_tokens} tokens to reason.\"\n",
    "\n",
    "    cot_output = pipe(\n",
    "        prompt,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        pad_token_id=pipe.tokenizer.eos_token_id,\n",
    "        num_beams=5,\n",
    "        early_stopping=True,\n",
    "        eos_token_id=pipe.tokenizer.eos_token_id,\n",
    "        temperature=0.5\n",
    "    )\n",
    "    cot_reasoning = cot_output[0]['generated_text']\n",
    "    prompt = f\"{cot_reasoning}\\n\\nBased on the above, reasoning what is the single, most likely answer choice? \\nAnswer using this format:\\n[X]\"\n",
    "    prompt += _build_final_instruction()\n",
    "    return prompt\n",
    "\n",
    "def five_shot_prompt(example: Example, no: int = 5) -> str:\n",
    "    prompt = _base_prompt()\n",
    "    prompt += \"\\nHere are some example questions from experts. Answer the final question yourself, following the format of the previous questions exactly.\\n\"\n",
    "    prompt += _prepare_examples(example=example, no=no)\n",
    "    prompt += \"\\n\\nNow your turn. Choose the correct option that answers the below question.\\n\"\n",
    "    prompt += _build_question_section(example)\n",
    "    prompt += _build_instructions()\n",
    "    prompt += _build_final_instruction()\n",
    "    return prompt\n",
    "\n",
    "def zero_shot_prompt(example: Example) -> str:\n",
    "    prompt = _base_prompt() + _build_question_section(example)\n",
    "    prompt += _build_instructions()\n",
    "    prompt += _build_final_instruction()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # delete empty rows\n",
    "# df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove ',' from df[Answer]\n",
    "# df['Answer'] = df['Answer'].str.replace(',', '')\n",
    "# df.to_csv(\"../dataset/cleaned_dataset.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e1bc1c290b4d26a88d1de2908ce083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "model_name =  \"meta-llama/Llama-3.2-3B-Instruct\"# \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "pipe = pipeline (\"text-generation\", model=model_name, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model pipeline\n",
    "#pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-1B-Instruct\", device='cuda')\n",
    "\n",
    "def runner(n=1, prompt_type='zero_shot_prompt'):\n",
    "   # model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "    for i in tqdm(range(n), desc=\"Iterations\"):\n",
    "        results = []\n",
    "        for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "            try:\n",
    "                question = row['Question']\n",
    "                right_answer = row['Answer']\n",
    "                # selecting distractions.\n",
    "                option = []\n",
    "                option.append(right_answer)\n",
    "                while len(option) < 4:\n",
    "                    distractor = df.sample(1)['Answer'].values[0]\n",
    "                    if distractor not in option and distractor != right_answer:\n",
    "                        option.append(distractor)\n",
    "\n",
    "                # print(f\"Question: {question}\")\n",
    "                # print(f\"Right Answer: {right_answer}\")\n",
    "                # print(f\"Options: {option}\")\n",
    "                # print(len(option)) \n",
    "                # break\n",
    "\n",
    "                # Create an example\n",
    "                random.shuffle(option)\n",
    "                # Right option is \n",
    "                right_option_index = option.index(right_answer)\n",
    "                right_option_letter = chr(ord('A') + right_option_index)\n",
    "                #print(f\"\\n\\nRight option index: {right_option_letter}\")\n",
    "                \n",
    "                example = Example(question, \n",
    "                                  option[0], \n",
    "                                  option[1], \n",
    "                                  option[2], \n",
    "                                  option[3]\n",
    "                                )\n",
    "                \n",
    "                # Depending on prompt_type, generate the prompt using the integrated functions\n",
    "                if prompt_type == 'zero_shot_prompt':\n",
    "                    prompt = zero_shot_prompt(example)\n",
    "                elif prompt_type == 'five_shot_prompt':\n",
    "                    n_examples = 5\n",
    "                    prompt =  five_shot_prompt(example, n_examples)\n",
    "                elif prompt_type == 'chain_of_thought_prompt':\n",
    "                    thinking_tokens = 512\n",
    "                    prompt = chain_of_thought_prompt(example, thinking_tokens)\n",
    "                else:\n",
    "                    # Default behavior (original prompt)\n",
    "                    print(\"SELECTING DEFAULT PROMPTING TECHNIQUE\")\n",
    "                    prompt = zero_shot_prompt(example)\n",
    "\n",
    "                #print(prompt)\n",
    "                #break\n",
    "                # Generate the model's response\n",
    "                response = pipe(\n",
    "                    prompt,\n",
    "                    max_new_tokens=15, # Preferably 15\n",
    "                    pad_token_id=pipe.tokenizer.eos_token_id,\n",
    "                    num_beams=5,\n",
    "                    early_stopping=True,\n",
    "                    eos_token_id=pipe.tokenizer.eos_token_id,\n",
    "                    temperature=0.1\n",
    "                )\n",
    "\n",
    "                # Extract generated text\n",
    "                generated_text = response[0][\"generated_text\"]\n",
    "                #print(generated_text)\n",
    "                answer_portion = generated_text.split(\"else.\")[1]\n",
    "                match = re.search(r'[A-D]', answer_portion)\n",
    "                if match:\n",
    "                    model_answer_letter = match.group()\n",
    "                else:\n",
    "                    model_answer_letter = 'NA'\n",
    "                \n",
    "                                \n",
    "                if index == 0 and i==0:\n",
    "                    print(generated_text)\n",
    "                    print(\"Correct Ans: \", right_answer)\n",
    "                    print(\"Model Replied with: \", model_answer_letter)\n",
    "                    \n",
    "                is_correct = (right_option_letter and model_answer_letter) and right_option_letter.lower() == model_answer_letter.lower()\n",
    "\n",
    "                result = {\n",
    "                    \"iteration\": i,\n",
    "                    \"id\": index,\n",
    "                    \"model\": model_name,\n",
    "                    \"prompt_type\": prompt_type,\n",
    "                    \"question\": question,\n",
    "                    \"right_answer\": right_answer,\n",
    "                    \"right_answer_option\": right_option_letter,\n",
    "                    \"model_answer_letter\": model_answer_letter,\n",
    "                    \"generated_text\": generated_text,\n",
    "                    \"is_correct\": str(is_correct)\n",
    "                }\n",
    "                results.append(result)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {index}: {e}\")\n",
    "                print(generated_text)\n",
    "                continue \n",
    "\n",
    "        # Save the results\n",
    "        if not os.path.exists(f\"results/base_model_eval/{prompt_type}/{model_name.split('/')[1]}\"):\n",
    "            os.makedirs(f\"results/base_model_eval/{prompt_type}/{model_name.split('/')[1]}\")\n",
    "\n",
    "        with open(f\"results/base_model_eval/{prompt_type}/{model_name.split('/')[1]}/output_{i}.json\", \"w\") as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "    \n",
    "        print(\"Evaluation complete. Results saved to output.json.\")    \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520a32b77fc14fbca36cb24634f6b709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ffe6d30c5f64bccbf914ca6293696e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Act as an expert legal assistant with comprehensive knowledge of statutory law and case precedent. Analyze the following legal question carefully, then select the correct answer from the given options through rigorous legal reasoning.\n",
      "Here are some example questions from experts. Answer the final question yourself, following the format of the previous questions exactly.\n",
      "--- START OF EXAMPLES ---\n",
      "\n",
      "\n",
      "Question: How do I check the status of my Form I-765 application?\n",
      "Choices:\n",
      "(A) Yes you get a new OPT period for each higher degree level (bachelors masters PhD).\n",
      "(B) After submitting your application online you can monitor its status through your USCIS online account dashboard.\n",
      "(C) Generally CPT and OPT require U.S.-based employment. Remote work may be allowed if the employer has a U.S. presence and follows employment regulations.\n",
      "(D) No STEM OPT requires paid employment with an E-Verify employer.\n",
      "The correct answer is (B)\n",
      "\n",
      "Question: nan\n",
      "Choices:\n",
      "(A) Yes if you have a STEM-designated degree you can apply for a 24-month STEM OPT extension making your total OPT period 36 months.\n",
      "(B) Yes they must complete Form I-983 Training Plan.\n",
      "(C) If denied you must leave the U.S. unless you apply for another visa or transfer to another school.\n",
      "(D) nan\n",
      "The correct answer is (D)\n",
      "\n",
      "Question: Can I do CPT and OPT at the same time?\n",
      "Choices:\n",
      "(A) Yes you get a new OPT period for each higher degree level (bachelors masters PhD).\n",
      "(B) No you cannot be on CPT and OPT simultaneously.\n",
      "(C) If your employer files your H-1B petition before your OPT expires you can continue working until October 1st when H-1B status begins.\n",
      "(D) Yes but its a long process and you may need an employer to sponsor you for a work visa (H-1B) first.\n",
      "The correct answer is (B)\n",
      "\n",
      "Question: What happens if my visa expires but my I-20 is still valid?\n",
      "Choices:\n",
      "(A) No you must be physically present in the U.S. when you submit your OPT application.\n",
      "(B) You can stay in the U.S. but if you travel outside you need to renew your visa before returning.\n",
      "(C) Yes but you must get approval from your DSO and academic department and it must align with your programs requirements.\n",
      "(D) No USCIS does not offer premium processing for standard OPT applications.\n",
      "The correct answer is (B)\n",
      "\n",
      "Question: Can I apply for OPT if I have a pending Green Card application?\n",
      "Choices:\n",
      "(A) No you must wait for approval and receive an updated I-20 with CPT authorization before starting work.\n",
      "(B) The fee is $470 for OPT and STEM OPT.\n",
      "(C) Yes but you must still maintain F-1 status until your Green Card is approved.\n",
      "(D) No CPT is employer-specific. If you want to change employers you need to apply for a new CPT authorization.\n",
      "The correct answer is (C)\n",
      "\n",
      "--- END OF EXAMPLES ---\n",
      "\n",
      "\n",
      "Now your turn. Choose the correct option that answers the below question.\n",
      "\n",
      "\n",
      "Question: How do I apply for CPT?\n",
      "Choices:\n",
      "(A) You must get approval from your Designated School Official (DSO) and submit a CPT request form along with an offer letter from your employer.\n",
      "(B) CPT is for internships or practical training while you are still studying whereas OPT is post-graduation work authorization.\n",
      "(C) CPT approval typically takes 510 business days after submitting the required documents to your Designated School Official (DSO).\n",
      "(D) Only if you apply for a Leave of Absence and you may need to leave the U.S. during this period.\n",
      "\n",
      "\n",
      "        Instructions:\n",
      "        1. Conduct thorough legal analysis of all options\n",
      "        2. Consider relevant statutes, regulations, and judicial interpretations\n",
      "        3. Identify potential ambiguities or counterarguments\n",
      "        4. Select only the BEST supported answer\n",
      "        5. Respond SOLELY with the correct letter (A-D)\n",
      "\n",
      "        Answer using this format:\n",
      "        [X]\n",
      "\n",
      "Please reply only with the correct option, do not say anything else.\" \n",
      "\n",
      "(I'll wait for your response) \n",
      "\n",
      "(Note: I'll provide the correct answer after your response) \n",
      "\n",
      "Please go ahead and answer the question. \n",
      "\n",
      "(Note: I'll wait for your response) \n",
      "\n",
      "(Note: I'll wait for your response) \n",
      "\n",
      "(Note: I'll wait for your response) \n",
      "\n",
      "(Note: I'll wait for your response) \n",
      "\n",
      "(Note: I'll wait for your response) \n",
      "\n",
      "(Note: I'll wait for your response) \n",
      "\n",
      "(Note: I'll wait for your response) \n",
      "\n",
      "(Note: I'll wait for your response) \n",
      "\n",
      "(Note: I'll wait for your response) \n",
      "\n",
      "(Note: I'll wait for your response) \n",
      "\n",
      "(Note: I'll wait for your response) \n",
      "\n",
      "(Note: I'll wait for your response)\n",
      "Correct Ans:  You must get approval from your Designated School Official (DSO) and submit a CPT request form along with an offer letter from your employer.\n",
      "Model Replied with:  NA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Results saved to output.json.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe84bd6509e74c46ad3e34c13257aeec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Results saved to output.json.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f5e5d22022412b9fb211dab35c2186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Results saved to output.json.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "171af0537c604feeb80df148d6586900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Results saved to output.json.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2016c2baf14b0d94c88c73d80013a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Results saved to output.json.\n"
     ]
    }
   ],
   "source": [
    "runner(5, 'five_shot_prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ../results/base_model_eval/zero_shot_prompt/Llama-3.1-8B-Instruct/output_1.json\n",
      "Total is_correct = True: 95\n",
      "Total is_correct = False: 36\n",
      "Total is_correct = NA: 0\n",
      "----------------------------------------\n",
      "File: ../results/base_model_eval/zero_shot_prompt/Llama-3.1-8B-Instruct/output_0.json\n",
      "Total is_correct = True: 104\n",
      "Total is_correct = False: 27\n",
      "Total is_correct = NA: 0\n",
      "----------------------------------------\n",
      "File: ../results/base_model_eval/zero_shot_prompt/Llama-3.1-8B-Instruct/output_4.json\n",
      "Total is_correct = True: 101\n",
      "Total is_correct = False: 30\n",
      "Total is_correct = NA: 0\n",
      "----------------------------------------\n",
      "File: ../results/base_model_eval/zero_shot_prompt/Llama-3.1-8B-Instruct/output_3.json\n",
      "Total is_correct = True: 99\n",
      "Total is_correct = False: 32\n",
      "Total is_correct = NA: 0\n",
      "----------------------------------------\n",
      "File: ../results/base_model_eval/zero_shot_prompt/Llama-3.1-8B-Instruct/output_2.json\n",
      "Total is_correct = True: 95\n",
      "Total is_correct = False: 36\n",
      "Total is_correct = NA: 0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "prompt_type = 'zero_shot_prompt' #\"chain_of_thought_prompt\"  # five_shot_prompt # zero_shot_prompt\n",
    "#model_name = 'meta-llama/Llama-3.2-3B-Instruct'\n",
    "#model_name = \"deepseek-ai/deepseek-llm-7b-chat\" \n",
    "model_name =  \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# Construct the directory path\n",
    "#directory = f\"results/base_model_eval/{prompt_type}/{model_name.split('/')[1]}/\" # When running on Jetstream\n",
    "directory = f\"../results/base_model_eval/{prompt_type}/{model_name.split('/')[1]}/\" # When running in VS CODE\n",
    "\n",
    "# Find all JSON files matching output_*.json pattern\n",
    "json_files = glob.glob(os.path.join(directory, \"output_*.json\"))\n",
    "\n",
    "# Process each JSON file\n",
    "for file_path in json_files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Count occurrences of is_correct = True and is_correct = False\n",
    "    true_count = sum(1 for item in data if item.get(\"is_correct\") == 'True') # model answer == actual answer\n",
    "    false_count = sum(1 for item in data if item.get(\"is_correct\") == 'False') # model answer != actual answer\n",
    "    na_count = sum(1 for item in data if item.get(\"is_correct\") == 'NA') # Model was not able to answer/ Answer not found in response\n",
    "    \n",
    "    print(f\"File: {file_path}\")\n",
    "    print(f\"Total is_correct = True: {true_count}\")\n",
    "    print(f\"Total is_correct = False: {false_count}\")\n",
    "    print(f\"Total is_correct = NA: {na_count}\")\n",
    "    print(\"-\" * 40) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
