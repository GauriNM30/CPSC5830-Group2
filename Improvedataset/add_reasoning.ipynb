{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv()\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is a high school diploma required for an F-1 v...</td>\n",
       "      <td>A high school diploma or its equivalent is gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is it important to memorize my SEVIS ID?</td>\n",
       "      <td>It's crucial to know your SEVIS ID, as it's yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is proof of housing required at the port of en...</td>\n",
       "      <td>While proof of housing is not always required ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What document does a school provide for an F-1...</td>\n",
       "      <td>A school provides Form I-20, a Certificate of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What if I plan to do research collaboration wi...</td>\n",
       "      <td>If asked about potential research collaboratio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  Is a high school diploma required for an F-1 v...   \n",
       "1           Is it important to memorize my SEVIS ID?   \n",
       "2  Is proof of housing required at the port of en...   \n",
       "3  What document does a school provide for an F-1...   \n",
       "4  What if I plan to do research collaboration wi...   \n",
       "\n",
       "                                              Answer  \n",
       "0  A high school diploma or its equivalent is gen...  \n",
       "1  It's crucial to know your SEVIS ID, as it's yo...  \n",
       "2  While proof of housing is not always required ...  \n",
       "3  A school provides Form I-20, a Certificate of ...  \n",
       "4  If asked about potential research collaboratio...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/cleaned_dataset_answer_improved.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinetunePreprocessor:\n",
    "    def __init__(self) -> None:\n",
    "        # Retrieve the API key from environment variables\n",
    "        api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "        if not api_key:\n",
    "            raise ValueError(\"GOOGLE_API_KEY environment variable is not set.\")\n",
    "        \n",
    "        # Configure the generative AI model\n",
    "        model_name = 'gemini-2.0-flash-exp'\n",
    "        genai.configure(api_key=api_key)\n",
    "\n",
    "        # Define the finetuning prompt\n",
    "        self.finetuning_prompt = \"\"\"Act as a legal expert analyzing a complex question. Generate detailed reasoning that leads to the provided answer. Follow these steps:\n",
    "\n",
    "1. **Question Understanding**:\n",
    "   - Break down the key legal concepts, jurisdictions, and implied context in the question\n",
    "   - Identify potential ambiguities or multiple interpretations\n",
    "\n",
    "2. **Core Analysis**:\n",
    "   - Explain the primary legal framework(s) applicable\n",
    "   - Reference relevant statutes, case law, and legal principles\n",
    "   - Outline logical steps connecting facts to legal conclusions\n",
    "\n",
    "3. **Alternative Perspectives**:\n",
    "   - Present 2-3 plausible counterarguments or different interpretations\n",
    "   - Consider opposing viewpoints and conflicting precedents\n",
    "   - Discuss edge cases or exceptional circumstances\n",
    "\n",
    "4. **Self-Reflection**:\n",
    "   - Evaluate the strength of each perspective\n",
    "   - Identify potential weaknesses in the main answer's reasoning\n",
    "   - Explain why the provided answer is preferable despite alternatives\n",
    "\n",
    "5. **Conclusion Synthesis**:\n",
    "   - Clearly restate how the reasoning supports the final answer\n",
    "   - Acknowledge any remaining uncertainties or limitations\n",
    "\n",
    "Format Requirements:\n",
    "- Use clear section headers without markdown\n",
    "- Maintain academic tone but avoid unnecessary jargon\n",
    "- Keep paragraphs concise (2-3 sentences)\n",
    "- Reference specific legal concepts when possible\n",
    "\n",
    "Input:\n",
    "Question: {question}\n",
    "Answer: {answer}\n",
    "\n",
    "Output: \n",
    "[Only provide the reasoning text using the specified structure]\"\"\"\n",
    "\n",
    "        # Initialize the generative model with the finetuning prompt\n",
    "        self.chat_model = genai.GenerativeModel(model_name, system_instruction=self.finetuning_prompt)\n",
    "\n",
    "\n",
    "    def generate_reasoning_new(self, df: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Generates reasoning for each question-answer pair in the DataFrame and saves the results to a CSV file.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): A DataFrame containing 'Question' and 'Answer' columns.\n",
    "        \"\"\"\n",
    "        output_file = '../dataset/cleaned_dataset_answer_improved_reasoned.csv'\n",
    "        max_retries = 3  # Maximum number of retries for a failed question\n",
    "        processed_rows = []\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            question = row['Question']\n",
    "            answer = row['Answer']\n",
    "            reasoning = None\n",
    "            retries = 0\n",
    "\n",
    "            while retries < max_retries:\n",
    "                try:\n",
    "                    # Generate reasoning using the chat model\n",
    "                    response = self.chat_model.generate_content(f\"Question: {question}\\nAnswer: {answer}\")\n",
    "                    time.sleep(3)  # Rate limiting\n",
    "                    reasoning = response.text\n",
    "                    break  # Exit retry loop on success\n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating reasoning for row {index}: {e}\")\n",
    "                    retries += 1\n",
    "                    if retries < max_retries:\n",
    "                        print(f\"Retrying ({retries}/{max_retries}) after 10 seconds...\")\n",
    "                        time.sleep(10)\n",
    "                    else:\n",
    "                        print(f\"Max retries reached. Setting reasoning to None for row {index}.\")\n",
    "                        reasoning = None\n",
    "                        break\n",
    "\n",
    "            # Prepare row for CSV saving\n",
    "            new_row = row.to_dict()\n",
    "            new_row['reasoning'] = reasoning\n",
    "            processed_rows.append(new_row)\n",
    "\n",
    "            # Rate limiting\n",
    "            time.sleep(3)\n",
    "            if index % 15 == 0:\n",
    "                time.sleep(10)  # Extra sleep every 15 rows\n",
    "\n",
    "            # Save progress every 50 rows\n",
    "            if len(processed_rows) >= 50:\n",
    "                self._save_chunk(processed_rows, output_file)\n",
    "                processed_rows = []\n",
    "\n",
    "        # Save remaining rows\n",
    "        if processed_rows:\n",
    "            self._save_chunk(processed_rows, output_file)\n",
    "\n",
    "    def _save_chunk(self, chunk: list, output_file: str) -> None:\n",
    "        \"\"\"Helper function to save a chunk of processed rows to CSV.\"\"\"\n",
    "        df_chunk = pd.DataFrame(chunk)\n",
    "        header = not os.path.exists(output_file)\n",
    "        try:\n",
    "            df_chunk.to_csv(output_file, mode='a', header=header, index=False)\n",
    "            print(f\"Saved {len(chunk)} rows to {output_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving chunk: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 rows to ../dataset/cleaned_dataset_answer_improved_reasoned.csv\n",
      "Saved 50 rows to ../dataset/cleaned_dataset_answer_improved_reasoned.csv\n",
      "Saved 50 rows to ../dataset/cleaned_dataset_answer_improved_reasoned.csv\n",
      "Saved 50 rows to ../dataset/cleaned_dataset_answer_improved_reasoned.csv\n",
      "Error generating reasoning for row 226: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n",
      "Retrying (1/3) after 10 seconds...\n",
      "Saved 50 rows to ../dataset/cleaned_dataset_answer_improved_reasoned.csv\n",
      "Saved 50 rows to ../dataset/cleaned_dataset_answer_improved_reasoned.csv\n",
      "Saved 50 rows to ../dataset/cleaned_dataset_answer_improved_reasoned.csv\n",
      "Error generating reasoning for row 399: 504 Deadline Exceeded\n",
      "Retrying (1/3) after 10 seconds...\n",
      "Saved 50 rows to ../dataset/cleaned_dataset_answer_improved_reasoned.csv\n",
      "Error generating reasoning for row 402: 504 Deadline Exceeded\n",
      "Retrying (1/3) after 10 seconds...\n",
      "Error generating reasoning for row 420: 504 Deadline Exceeded\n",
      "Retrying (1/3) after 10 seconds...\n",
      "Error generating reasoning for row 434: 504 Deadline Exceeded\n",
      "Retrying (1/3) after 10 seconds...\n",
      "Saved 50 rows to ../dataset/cleaned_dataset_answer_improved_reasoned.csv\n",
      "Error generating reasoning for row 462: 504 Deadline Exceeded\n",
      "Retrying (1/3) after 10 seconds...\n",
      "Saved 50 rows to ../dataset/cleaned_dataset_answer_improved_reasoned.csv\n",
      "Error generating reasoning for row 534: 504 Deadline Exceeded\n",
      "Retrying (1/3) after 10 seconds...\n",
      "Saved 50 rows to ../dataset/cleaned_dataset_answer_improved_reasoned.csv\n",
      "Error generating reasoning for row 553: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n",
      "Retrying (1/3) after 10 seconds...\n",
      "Saved 50 rows to ../dataset/cleaned_dataset_answer_improved_reasoned.csv\n",
      "Error generating reasoning for row 642: 504 Deadline Exceeded\n",
      "Retrying (1/3) after 10 seconds...\n",
      "Saved 50 rows to ../dataset/cleaned_dataset_answer_improved_reasoned.csv\n",
      "Error generating reasoning for row 666: 504 Deadline Exceeded\n",
      "Retrying (1/3) after 10 seconds...\n",
      "Error generating reasoning for row 680: 504 Deadline Exceeded\n",
      "Retrying (1/3) after 10 seconds...\n",
      "Saved 50 rows to ../dataset/cleaned_dataset_answer_improved_reasoned.csv\n",
      "Error generating reasoning for row 703: 504 Deadline Exceeded\n",
      "Retrying (1/3) after 10 seconds...\n",
      "Error generating reasoning for row 735: 504 Deadline Exceeded\n",
      "Retrying (1/3) after 10 seconds...\n",
      "Saved 50 rows to ../dataset/cleaned_dataset_answer_improved_reasoned.csv\n",
      "Saved 50 rows to ../dataset/cleaned_dataset_answer_improved_reasoned.csv\n",
      "Saved 50 rows to ../dataset/cleaned_dataset_answer_improved_reasoned.csv\n",
      "Saved 50 rows to ../dataset/cleaned_dataset_answer_improved_reasoned.csv\n",
      "Error generating reasoning for row 941: 504 Deadline Exceeded\n",
      "Retrying (1/3) after 10 seconds...\n",
      "Saved 50 rows to ../dataset/cleaned_dataset_answer_improved_reasoned.csv\n",
      "Saved 50 rows to ../dataset/cleaned_dataset_answer_improved_reasoned.csv\n"
     ]
    }
   ],
   "source": [
    "preprocessor = FinetunePreprocessor()\n",
    "preprocessor.generate_reasoning_new(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.read_csv('../dataset/cleaned_dataset_answer_improved_reasoned.csv')\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
