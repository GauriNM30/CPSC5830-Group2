{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86855830-df18-4918-b234-1c88ab72abad",
   "metadata": {},
   "source": [
    "# Answer:\n",
    "\n",
    "Evaluating Question: How can an international student on an F-1 visa maintain their status during graduate studies?\n",
    "\n",
    "Generated Answer: <|im_sep|>\n",
    "\n",
    "assistant: To maintain F-1 visa status during graduate studies, an international student must adhere to several key requirements:\n",
    "\n",
    "1. **Full-time enrollment**: Students must remain enrolled in a full-time course load as determined by their academic institution. This usually means taking the minimum number of credits required for their degree program.\n",
    "\n",
    "2. **Academic progress**: Maintain satisfactory academic standing. This means staying within the school's standards for grade point average, and completing coursework in a timely manner towards the degree.\n",
    "\n",
    "3. **Coursework relevance**: Ensure that the courses taken align with the student's field of study. This maintains alignment with the original visa purpose and avoids issues with maintaining status.\n",
    "\n",
    "4. **On-campus employment**: Follow guidelines for on-campus employment, which includes:\n",
    "   - Not displacing U.S. citizens or lawful permanent residents (LPRs) from their jobs.\n",
    "   - Employments must be for the school or for an educationally affiliated organization. Examples include school\n",
    "Evaluation Result: Question: How can an international student on an F-1 visa maintain their status during graduate studies?\n",
    "\n",
    "Expected Answer: To maintain F-1 status during graduate studies, an international student must enroll as a full-time student, make normal progress toward a degree, and comply with all rules and regulations set by their educational institution and the U.S. government. This includes not engaging in unauthorized employment and keeping documentation up to date.\n",
    "\n",
    "Generated Answer: <|im_sep|>\n",
    "\n",
    "assistant: To maintain F-1 visa status during graduate studies, an international student must adhere to several key requirements:\n",
    "\n",
    "1. **Full-time enrollment**: Students must remain enrolled in a full-time course load as determined by their academic institution. This usually means taking the minimum number of credits required for their degree program.\n",
    "\n",
    "2. **Academic progress**: Maintain satisfactory academic standing. This means staying within the school's standards for grade point average, and completing coursework in a timely manner towards the degree.\n",
    "\n",
    "3. **Coursework relevance**: Ensure that the courses taken align with the student's field of study. This maintains alignment with the original visa purpose and avoids issues with maintaining status.\n",
    "\n",
    "4. **On-campus employment**: Follow guidelines for on-campus employment, which includes:\n",
    "   - Not displacing U.S. citizens or lawful permanent residents (LPRs) from their jobs.\n",
    "   - Employments must be for the school or for an educationally affiliated organization. Examples include school\n",
    "\n",
    "Please evaluate the generated answer compared to the expected answer. Provide a score between 1 (poor) and 5 (excellent) along with a brief justification for your score.\n",
    "\n",
    "Score and Justification: Excellent 5/5\n",
    "The generated answer is comprehensive and answers the question accurately by listing out the requirements for maintaining F-1 visa status during graduate studies while providing additional context on each requirement.\n",
    "\n",
    "- It clearly highlights the importance of full-time enrollment, maintaining satisfactory academic standing, ensuring coursework relevance, and following guidelines for on-campus employment.\n",
    "- The answer also reinforces the need for alignment with the original visa purpose to avoid issues with maintaining status\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Evaluating Question: What is Curricular Practical Training (CPT) and how does it benefit F-1 students?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4aaaa8-0008-4cf3-8f07-b8b53553b08c",
   "metadata": {},
   "source": [
    "# Half precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "656d0550-4ff8-497e-94c2-2123c073e972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d8c6b729e54cf1aa9c5e9d30dff815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37b91d40296499b9b5618d83711bc90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_88042/4012614344.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "**Question:** What is the capital of Mongolia?\n",
      "**Expected Answer:** Oh, that's an interesting question! While I don't have information on that right now, I'd be delighted to help you with anything related to CPT, OPT, or maintaining your F-1 visa status. Is there anything I can assist you with in those areas?\n",
      "**Generated Answer:** This question is outside the scope of F-1 visa regulations, CPT, or OPT.\n",
      "**Score:** 4\n",
      "**Justification:** Detailed reason for the score\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "**Question:** Can you write a poem about a cat's adventure in space?\n",
      "**Expected Answer:** That sounds like a fun creative project! Unfortunately, I'm not able to generate poems, but I can certainly provide detailed information and guidance on CPT, OPT, and F-1 visa status maintenance. Perhaps we could explore some of your questions on those topics?\n",
      "**Generated Answer:** This question is outside the scope of F-1 visa regulations, CPT, or OPT.\n",
      "**Score:** 4\n",
      "**Justification:** Detailed reason for the score\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "**Question:** What is the current price of Bitcoin?\n",
      "**Expected Answer:** I don't have access to real-time financial data, but I'd be happy to discuss how financial matters might impact your F-1 status, if you have any questions. Or, if you have questions regarding CPT or OPT, please ask!\n",
      "**Generated Answer:** This question is outside the scope of F-1 visa regulations, CPT, or OPT.\n",
      "**Score:** 4\n",
      "**Justification:** Detailed reason for the score\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "**Question:** Tell me a recipe for chocolate chip cookies.\n",
      "**Expected Answer:** That sounds delicious! While I can't provide recipes, I can definitely help you navigate the complexities of CPT, OPT, and F-1 visa status maintenance. Do you have any specific concerns or questions about those topics?\n",
      "**Generated Answer:** This question is outside the scope of F-1 visa regulations, CPT, or OPT.\n",
      "**Score:** 4\n",
      "**Justification:** Detailed reason for the score\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "**Question:** Who won the 2023 World Series?\n",
      "**Expected Answer:** I don't follow sports results, but I'm ready to assist you with any questions you have about CPT, OPT, and maintaining your F-1 visa status. How can I help you today?\n",
      "**Generated Answer:** This question is outside the scope of F-1 visa regulations, CPT, or OPT.\n",
      "**Score:** 4\n",
      "**Justification:** Detailed reason for the score\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "**Question:** What are the symptoms of the common cold?\n",
      "**Expected Answer:** I'm not a medical professional, so I can't give medical advice. However, if you have questions about how a medical situation might affect your F-1 status, or if you need help with CPT or OPT, please feel free to ask!\n",
      "**Generated Answer:** This question is outside the scope of F-1 visa regulations, CPT, or OPT.\n",
      "**Score:** 4\n",
      "**Justification:** Detailed reason for the score\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "**Question:** What is the weather forecast for London tomorrow?\n",
      "**Expected Answer:** I don't have access to real-time weather information, but I'm here to help with any questions you have about CPT, OPT, and F-1 visa status maintenance. What's on your mind?\n",
      "**Generated Answer:** This question is outside the scope of F-1 visa regulations, CPT, or OPT.\n",
      "**Score:** 4\n",
      "**Justification:** Detailed reason for the score\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "**Question:** Explain the theory of relativity.\n",
      "**Expected Answer:** That's a fascinating topic! While I don't specialize in theoretical physics, I can provide detailed explanations and guidance on CPT, OPT, and F-1 visa status maintenance. Would you like to discuss any of those areas?\n",
      "**Generated Answer:** This question is outside the scope of F-1 visa regulations, CPT, or OPT.\n",
      "**Score:** 4\n",
      "**Justification:** Detailed reason for the score\n",
      "================================================================================\n",
      "\n",
      "Evaluation completed. Results saved to test_results2.json.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from dotenv import load_dotenv\n",
    "from RAG_With_QWEN import RAG  # Import your RAG class\n",
    "\n",
    "# Method to get the API key from the .env file\n",
    "def get_api_key(api_name):\n",
    "    env_path = \"../.dummy_env\"  # Adjust the path as needed\n",
    "    load_dotenv(env_path)  # Load the environment variables\n",
    "    return os.getenv(api_name)\n",
    "\n",
    "# -------------------------------\n",
    "# Setup Evaluator Model (Mistral)\n",
    "# -------------------------------\n",
    "CUSTOM_CACHE_DIR = \"/media/volume/vol-VisaWise/models/mistral_cache\"\n",
    "\n",
    "evaluator_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    cache_dir=CUSTOM_CACHE_DIR,\n",
    "    torch_dtype=torch.float16,\n",
    "    token=get_api_key('HF_GAURI')\n",
    ")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "evaluator_model.to(device)\n",
    "evaluator_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "evaluator_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    cache_dir=CUSTOM_CACHE_DIR,\n",
    "    token=get_api_key('HF_GAURI')\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Load QA Dataset from CSV\n",
    "# -------------------------------\n",
    "def load_qa_dataset(csv_file):\n",
    "    qa_dataset = []\n",
    "    with open(csv_file, newline='', encoding=\"utf-8\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            qa_dataset.append({\n",
    "                \"question\": row[\"Question\"],\n",
    "                \"expected_answer\": row[\"Expected Answer\"]\n",
    "            })\n",
    "    return qa_dataset[-8:]  # Keep only the last 8 rows\n",
    "\n",
    "qa_dataset = load_qa_dataset(\"RAG_Evaluation_Dataset.csv\")\n",
    "\n",
    "# -------------------------------\n",
    "# Define Evaluation Function\n",
    "# -------------------------------\n",
    "def evaluate_answer(question, generated_answer, expected_answer):\n",
    "    \"\"\"\n",
    "    Uses the evaluator model to compare the generated answer with the expected answer.\n",
    "    Extracts the full justification after \"Score:\" and \"Justification:\".\n",
    "    \"\"\"\n",
    "    eval_prompt = (\n",
    "        f\"Question: {question}\\n\\n\"\n",
    "        f\"Expected Answer: {expected_answer}\\n\\n\"\n",
    "        f\"Generated Answer: {generated_answer}\\n\\n\"\n",
    "        \"Evaluate the generated answer **strictly** by comparing it **only** to the expected answer provided above. \"\n",
    "        \"**Do not use any external knowledge, assumptions, or personal judgment about what the answer should be.** \"\n",
    "        \"Your evaluation must be based **solely** on whether the generated answer conveys the same meaning, tone, and intent as the expected answer, \"\n",
    "        \"even if the wording is different.\\n\\n\"\n",
    "        \"**Key Criteria:**\\n\"\n",
    "        \"- If the expected answer **refuses** to answer a question, the generated answer **must also refuse** in a similar way.\\n\"\n",
    "        \"- If the expected answer provides a redirection or context, the generated answer **should match the same intent and purpose.**\\n\"\n",
    "        \"- Minor differences in wording **should not** be penalized if the meaning remains the same.\\n\"\n",
    "        \"- Only deduct points if the generated answer changes the meaning, adds incorrect details, or omits key aspects.\\n\\n\"\n",
    "        \"Assign a score between **1 (poor) and 5 (excellent)** based **only** on this comparison.\\n\\n\"\n",
    "        \"**Response Format:**\\n\"\n",
    "        \"Score: [1-5]\\n\"\n",
    "        \"Justification: [Detailed reason for the score]\\n\\n\"\n",
    "        \"Example:\\n\"\n",
    "        \"Score: 4\\n\"\n",
    "        \"Justification: The generated answer is mostly correct but slightly different in tone.\\n\\n\"\n",
    "        \"Now, provide the evaluation:\\n\"\n",
    "    )\n",
    "\n",
    "    # Tokenize and move tokens to GPU\n",
    "    tokens = evaluator_tokenizer.encode(eval_prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Disable gradient calculations and use AMP for efficiency\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast():\n",
    "            generated_ids = evaluator_model.generate(tokens, max_new_tokens=100, do_sample=True)\n",
    "    \n",
    "    evaluation_text = evaluator_tokenizer.decode(generated_ids[0].tolist(), skip_special_tokens=True).strip()\n",
    "\n",
    "    # Extract score\n",
    "    score_match = re.search(r\"Score:\\s*(\\d+)\", evaluation_text, re.IGNORECASE)\n",
    "    score = int(score_match.group(1)) if score_match else None\n",
    "\n",
    "    # Extract justification\n",
    "    justification_match = re.search(r\"Justification:\\s*(.*)\", evaluation_text, re.IGNORECASE)\n",
    "    justification = justification_match.group(1).strip() if justification_match else \"?? Not found\"\n",
    "\n",
    "    return score, justification  # Return both score and justification separately\n",
    "\n",
    "# -------------------------------\n",
    "# Main Evaluation Routine\n",
    "# -------------------------------\n",
    "def main():\n",
    "    rag_model = RAG()\n",
    "    evaluations = []  \n",
    "    \n",
    "    for qa in qa_dataset:\n",
    "        question = qa[\"question\"]\n",
    "        expected_answer = qa[\"expected_answer\"]\n",
    "        \n",
    "        # Generate answer using your RAG model\n",
    "        generated_answer = rag_model.generate_answer(question)\n",
    "        \n",
    "        # Evaluate the generated answer\n",
    "        score, justification = evaluate_answer(question, generated_answer, expected_answer)\n",
    "        \n",
    "        # Print output in a structured format (only once)\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"**Question:** {question}\")\n",
    "        print(f\"**Expected Answer:** {expected_answer}\")\n",
    "        print(f\"**Generated Answer:** {generated_answer}\")\n",
    "        print(f\"**Score:** {score if score is not None else '?? Not found'}\")\n",
    "        print(f\"**Justification:** {justification}\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        # Store results for JSON output\n",
    "        evaluations.append({\n",
    "            \"question\": question,\n",
    "            \"expected_answer\": expected_answer,\n",
    "            \"generated_answer\": generated_answer,\n",
    "            \"score\": score,\n",
    "            \"justification\": justification\n",
    "        })\n",
    "    \n",
    "    # Save evaluation results to a JSON file\n",
    "    with open(\"Evaluation_Results_Without_Finetuning.json\", \"w\") as outfile:\n",
    "        json.dump(evaluations, outfile, indent=4)\n",
    "    \n",
    "    print(\"\\nEvaluation completed. Results saved to test_results2.json.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3641b757-3f25-4bd2-b16d-5c9adb412a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install google.generativeai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79c752e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
